{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMqwfn8C+ptWNm+3vaurx49"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ue0rsaQM9TsR"
      },
      "outputs": [],
      "source": [
        "# Prompt (GAME format) — _parse_word_tables.py_\n",
        "\n",
        "> **Purpose**\n",
        "> Feed this prompt to an LLM-agent so it will generate a ready-to-run script `parse_word_tables.py`.\n",
        "> The script downloads a Google Docs/Drive file as `.docx`, extracts every table, normalises column names, merges them, and stores the result in `/content/parsing_word.csv`.\n",
        "\n",
        "---\n",
        "\n",
        "# How to use\n",
        "\n",
        "1. Open your favourite LLM playground / API client.\n",
        "2. Copy-paste the entire prompt below **as is**.\n",
        "3. Run once — the assistant should respond **only with Python code** (no extra text).\n",
        "4. Save the returned code as `parse_word_tables.py`.\n",
        "5. In Google Colab (or any environment with `python-docx`, `pandas`, `gdown`):\n",
        "   ```python\n",
        "   !pip install python-docx pandas gdown\n",
        "   !python parse_word_tables.py\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The promt\n",
        "<system>\n",
        "You are a professional Python developer and an expert in processing Word documents. Respond with valid code only—no extra commentary.\n",
        "</system>\n",
        "\n",
        "<user>\n",
        "# Goals\n",
        "1. Produce a single file **parse_word_tables.py**.\n",
        "2. The script must:\n",
        "   • accept a Google Docs/Drive link;\n",
        "   • download the document as `.docx`;\n",
        "   • extract every table;\n",
        "   • rename headers to the `w_*` pattern according to a mapping table;\n",
        "   • merge the tables;\n",
        "   • save the result to `/content/parsing_word.csv` encoded as `utf-8-sig`;\n",
        "   • print the CSV path and the first rows of the DataFrame.\n",
        "\n",
        "# Actions\n",
        "Write clean Python code containing:\n",
        "```python\n",
        "from __future__ import annotations\n",
        "import os, re, json\n",
        "import pandas as pd\n",
        "import docx\n",
        "import gdown\n",
        "\n",
        "DL_DIR = \"/content\"\n",
        "DOC_PATH = os.path.join(DL_DIR, \"source.docx\")\n",
        "CSV_OUT  = os.path.join(DL_DIR, \"parsing_word.csv\")\n",
        "\n",
        "!pip install python-docx pandas gdown\n",
        "\n",
        "\n",
        "# Code: install dependencies & sample run\n",
        "\n",
        "```python\n",
        "#@title Install dependencies & sample run\n",
        "!pip install -q python-docx pandas gdown\n",
        "\n",
        "# Ensure the generated script exists\n",
        "if not os.path.exists(\"parse_word_tables.py\"):\n",
        "    raise FileNotFoundError(\n",
        "        \"Generate parse_word_tables.py with the LLM first, then upload it to Colab!\"\n",
        "    )\n",
        "\n",
        "# Interactive run (prompts for a Google Docs/Drive link)\n",
        "!python parse_word_tables.py\n"
      ],
      "metadata": {
        "id": "x6pbK3vr9n9o"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}